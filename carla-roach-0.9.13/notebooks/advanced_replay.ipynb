{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/vihaan-devel/carla/sip-report-gen/carla-roach-0.9.13/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import carla\n",
    "import yaml\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import glob\n",
    "from PIL import Image, ImageSequence\n",
    "\n",
    "project_directory = os.path.split(os.getcwd())[0] + '/'\n",
    "print(project_directory)\n",
    "sys.path.append(project_directory)\n",
    "\n",
    "import utils_cogmod\n",
    "from utils_cogmod.server_utils import CarlaServerManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get user input on which accident they would like to analyze\n",
    "\n",
    "def user_input():\n",
    "    global town\n",
    "    global traffic_density\n",
    "    global driver_condition\n",
    "    global trial_num\n",
    "    \n",
    "    town = int(input(\"Town04 (4) or Town05 (5)?\"))\n",
    "    traffic_density = int(input(\"Low (1) or Medium (2) or High (3) traffic density?\"))\n",
    "    date = int(input(\"Which set of tests would you like to select, 00-06-31 (1), 00-14-25 (2), 03-03-02 (3), 23-40-09 (4)?\"))\n",
    "    driver_condition = int(input(\"Normal (1) or Distracted (2)?\"))\n",
    "    trial_num = input(\"0 or 1 or 2 or 3 or 4\")\n",
    "\n",
    "    if town == 4:\n",
    "        town = \"Town04\"\n",
    "    elif town == 5:\n",
    "        town = \"Town05\"\n",
    "\n",
    "    if traffic_density == 1:\n",
    "        traffic_density = \"low\"\n",
    "    elif traffic_density == 2:\n",
    "        traffic_density = \"medium\"\n",
    "    elif traffic_density == 3:\n",
    "        traffic_density = \"high\"\n",
    "\n",
    "    if date == 1:\n",
    "        date = \"00-06-31\"\n",
    "    elif date == 2:\n",
    "        date = \"00-14-25\"\n",
    "    elif date == 3:\n",
    "        date = \"03-03-02\"\n",
    "    elif date == 4:\n",
    "        date = \"23-40-09\"\n",
    "\n",
    "    if driver_condition == 1:\n",
    "        driver_condition = \"normal\"\n",
    "    elif driver_condition == 2:\n",
    "        driver_condition = \"distracted\"\n",
    "\n",
    "    folder = \"CogMod-v0_\" + town + \"_\" + traffic_density + \"_simple\"\n",
    "    file_path = driver_condition + \"_1_repeat_\" + trial_num\n",
    "\n",
    "    print(\"Town: {}, Traffic Density: {}, Date: {}, Driver Condition: {}, Trial Number: {}, Folder: {}, File Path: {}\".format(town, traffic_density, date, driver_condition, trial_num, folder, file_path))\n",
    "    \n",
    "    return town, traffic_density, date, driver_condition, trial_num, folder, file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up config_path and Carla client\n",
    "\n",
    "def read_config(config_path):\n",
    "    with open(config_path, 'r') as file:\n",
    "        cfg = yaml.safe_load(file)\n",
    "    return cfg\n",
    "\n",
    "def init_client(host, port):\n",
    "    try:\n",
    "        client = carla.Client(host, port)\n",
    "        print(f\"client connected to {host}:{port}\")\n",
    "        print(f\"client.get_server_version(): {client.get_server_version()}, client.get_client_version(): {client.get_client_version()}\")\n",
    "        client.set_timeout(60.0)\n",
    "    except RuntimeError as re:\n",
    "        if \"timeout\" not in str(re) and \"time-out\" not in str(re):\n",
    "            print(\"Could not connect to Carla server because:\", re)\n",
    "        client = None \n",
    "    return client\n",
    "\n",
    "# Assuming 'client' is already initialized and is an instance of carla.Client\n",
    "# The path to your recorder log file\n",
    "\n",
    "def run_replay(config_path, recorder_file_path, actor_id, start_time, duration):\n",
    "    cfg = read_config(config_path)\n",
    "    # server_manager = CarlaServerManager(cfg['carla_sh_path'], cfg['port'], t_sleep=5)\n",
    "    # server_manager.stop()\n",
    "    # server_manager.start()\n",
    "\n",
    "    client = init_client(cfg['host'], cfg['port'])\n",
    "    # Check if file exists\n",
    "    try:\n",
    "        with open(recorder_file_path, 'r') as file:\n",
    "            print(f\"File found: {recorder_file_path}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {recorder_file_path}\")\n",
    "        exit()\n",
    "    try:\n",
    "        # Corrected call to replay_file\n",
    "        replay_result = client.replay_file(\n",
    "            recorder_file_path,\n",
    "            time_start=start_time,  # Explicitly specifying as double\n",
    "            duration=duration,    # Explicitly specifying as double\n",
    "            follow_id=actor_id,     # This is already an int, but making sure it's clearly specified\n",
    "            replay_sensors=True  # Assuming you want to replay sensors, adjust as necessary\n",
    "        )\n",
    "        print(\"Replaying recorded log file...\", replay_result)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while trying to replay the file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the Carla server\n",
    "\n",
    "def carla_init():\n",
    "    global cfg\n",
    "    global server_manager\n",
    "    cfg = read_config(config_path)\n",
    "    server_manager = CarlaServerManager(cfg['carla_sh_path'], cfg['port'], t_sleep=5)\n",
    "    server_manager.stop()\n",
    "    server_manager.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the Carla accident/client\n",
    "\n",
    "def carla_client():\n",
    "    global client\n",
    "    client = init_client(cfg['host'], cfg['port'])\n",
    "\n",
    "    all_info = client.show_recorder_file_info(recorder_file_path, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate all crashes in log file\n",
    "\n",
    "def crash_gen():\n",
    "    global collision_info\n",
    "    collision_info = client.show_recorder_collisions(recorder_file_path, \"h\", \"v\")\n",
    "\n",
    "    print(type(collision_info))\n",
    "    print(len(collision_info))\n",
    "\n",
    "    print(collision_info.index(\"Id\"))\n",
    "    x = collision_info.index(\"Id\")\n",
    "    print(collision_info[x + 100:x + 104])\n",
    "\n",
    "    print(collision_info)\n",
    "\n",
    "    actor_id = int(collision_info[x + 100:x + 104])\n",
    "    return actor_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets gaze direction and other data at time of the crash\n",
    "\n",
    "def crash_info():\n",
    "    collision_info = client.show_recorder_collisions(recorder_file_path, \"h\", \"v\")\n",
    "\n",
    "    lines = collision_info.splitlines()\n",
    "\n",
    "    filename = recorder_file_path[: len(recorder_file_path) - 3] + 'csv'\n",
    "    filename2 = recorder_file_path[: len(recorder_file_path) - 3] + 'json'\n",
    "\n",
    "    f = open(filename2)\n",
    "    data = json.load(f)\n",
    "\n",
    "    collision_vehicles = data['hero']['collisions_vehicle']\n",
    "    collision_pedestrian = data['hero']['collisions_pedestrian']\n",
    "\n",
    "    valid_gazes = 0\n",
    "    time_list = []\n",
    "    other_actor_list = []\n",
    "\n",
    "    if (len(lines) > 7):\n",
    "        for i in range(len(lines) - 8):\n",
    "            error_count = 0\n",
    "\n",
    "            j = i + 5\n",
    "            line = lines[j].strip()\n",
    "            time = int(line.split()[0])\n",
    "\n",
    "            if (i == 0):\n",
    "                time_prior = 0\n",
    "            else:\n",
    "                line_prior = lines[j - 1].strip()\n",
    "                time_prior = int(line_prior.split()[0])\n",
    "\n",
    "            if (time_prior >= time - 3 and time_prior <= time + 3):\n",
    "                error_count += 1\n",
    "\n",
    "            row_num = time + 1\n",
    "            row_num_prior = time_prior + 1\n",
    "            counter = 0\n",
    "            counter_prior = 0\n",
    "\n",
    "            with open(filename, mode = 'r') as file:\n",
    "                csv_reader = csv.reader(file)\n",
    "                header = next(csv_reader)\n",
    "\n",
    "                for row in csv_reader:\n",
    "                    counter_prior += 1\n",
    "                    if counter_prior == row_num_prior:\n",
    "                        prior_gaze = row[13]\n",
    "                        \n",
    "            with open(filename, mode = 'r') as file:\n",
    "                csv_reader = csv.reader(file)\n",
    "                header = next(csv_reader)\n",
    "\n",
    "                for row in csv_reader:\n",
    "                    counter += 1\n",
    "                    if counter == row_num:\n",
    "                        gaze = row[13]\n",
    "\n",
    "                        if prior_gaze == gaze:\n",
    "                            error_count += 1\n",
    "                        break\n",
    "\n",
    "            if error_count == 2:\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Information about crash {valid_gazes + 1} in this experiment on the Carla simulator:\")\n",
    "                \n",
    "                print()\n",
    "\n",
    "                print(\"Gaze direction at time of crash: {}\".format(row[13]))\n",
    "\n",
    "                intensity = collision_vehicles[valid_gazes].get('intensity')\n",
    "                print(\"Intensity: {}\".format(intensity))\n",
    "\n",
    "                print(\"Time: {}\".format(time))\n",
    "            \n",
    "                step = collision_vehicles[valid_gazes].get('step')\n",
    "                print(\"Step: {}\".format(step))\n",
    "\n",
    "                simulation_time = collision_vehicles[valid_gazes].get('simulation_time')\n",
    "                print(\"Simulation Time: {}\".format(simulation_time))\n",
    "\n",
    "                collision_type = collision_vehicles[valid_gazes].get('collision_type')\n",
    "                print(\"Collision Type: {}\".format(collision_type))\n",
    "\n",
    "                other_actor_id = collision_vehicles[valid_gazes].get('other_actor_id')\n",
    "                print(\"Other Actor ID: {}\".format(other_actor_id))\n",
    "\n",
    "                other_actor_type_id = collision_vehicles[valid_gazes].get('other_actor_type_id')\n",
    "                print(\"Other Actor Type ID: {}\".format(other_actor_type_id))\n",
    "\n",
    "                print()\n",
    "\n",
    "                valid_gazes += 1\n",
    "\n",
    "                time_list.append(time)\n",
    "                other_actor_list.append(other_actor_id)\n",
    "    \n",
    "    return gaze, intensity, time, time_list, valid_gazes, filename, filename2, step, simulation_time, collision_type, other_actor_id, other_actor_list, other_actor_type_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing actor_id's of ego vehicles in all recorded crashes and other basic crash information\n",
    "\n",
    "def store_basic_crash_info():\n",
    "    file_path_basic_data = project_directory + \"crash_info_basic.csv\"\n",
    "\n",
    "    file_exists = os.path.exists(file_path_basic_data)\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for i in range(len(time_list)):\n",
    "        crash_num = str(i + 1)\n",
    "        data.append({\"Crash # in Log File\": crash_num, \"Town\": town, \"Traffic Density\": traffic_density, \"Driver Condition\": driver_condition, \"Date\": date, \"Trial Number\": trial_num, \"Ego Actor ID\": actor_id, \"Other Actor ID\": other_actor_id})\n",
    "\n",
    "    # Write to a CSV file\n",
    "    with open(file_path_basic_data, \"a\", newline=\"\") as csvfile:\n",
    "        fieldnames = [\"Crash # in Log File\", \"Town\", \"Traffic Density\", \"Driver Condition\", \"Date\", \"Trial Number\", \"Ego Actor ID\", \"Other Actor ID\"]  # Define column headers\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "\n",
    "        writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CSV generation\n",
    "\n",
    "def csv_generation():\n",
    "    csv_path = project_directory + r\"outputs/experiment_1/\" + date + r\"/diagnostics/\" + folder\n",
    "\n",
    "    csv_name = file_path + \"_replay.csv\"\n",
    "\n",
    "    full_csv_path = os.path.join(csv_path, csv_name)\n",
    "\n",
    "    crash_num = 0\n",
    "\n",
    "    for i in range(len(time_list)):\n",
    "        time = time_list[i]\n",
    "        other_actor_id = other_actor_list[i]\n",
    "\n",
    "        start = time - 2\n",
    "        end = time + 2\n",
    "\n",
    "        first_time = True\n",
    "        first_time_distance = 0\n",
    "\n",
    "        oldh_x = 0\n",
    "        oldh_y = 0\n",
    "        oldh_z = 0\n",
    "        oldo_x = 0\n",
    "        oldo_y = 0\n",
    "        oldo_z = 0\n",
    "\n",
    "        velocityh = 0\n",
    "        velocityo = 0\n",
    "        oldvelocityh = 0\n",
    "        oldvelocityo = 0\n",
    "\n",
    "        accelerationh = 0\n",
    "        accelerationo = 0\n",
    "\n",
    "        world = client.get_world()\n",
    "\n",
    "        while start < end:\n",
    "            start = start + 0.1\n",
    "            client.replay_file(\n",
    "                recorder_file_path,\n",
    "                time_start = start,  # Explicitly specifying as double\n",
    "                duration = 0.01,    # Explicitly specifying as double\n",
    "                follow_id = actor_id,     # This is already an int, but making sure it's clearly specified\n",
    "                replay_sensors = True  # Assuming you want to replay sensors, adjust as necessary\n",
    "            )\n",
    "        \n",
    "            hero = world.get_actor(actor_id)\n",
    "            other_vehicle = world.get_actor(other_actor_id)\n",
    "\n",
    "            print(start)\n",
    "\n",
    "            print(f\"Velocity hero = {velocityh}\")\n",
    "            print(f\"Velocity other = {velocityo}\")\n",
    "\n",
    "            print(f\"Acceleration hero = {accelerationh}\")\n",
    "            print(f\"Acceleration other = {accelerationo}\")\n",
    "\n",
    "            with open(full_csv_path, 'a', newline = '') as file:\n",
    "                writer = csv.writer(file)\n",
    "\n",
    "                if first_time_distance == 0:\n",
    "                    first_time_distance += 1\n",
    "\n",
    "                    oldh_x = hero.get_location().x\n",
    "                    oldh_y = hero.get_location().y\n",
    "                    oldh_z = hero.get_location().z\n",
    "\n",
    "                    oldo_x = other_vehicle.get_location().x\n",
    "                    oldo_y = other_vehicle.get_location().y\n",
    "                    oldo_z = other_vehicle.get_location().z\n",
    "\n",
    "                    continue\n",
    "                else:\n",
    "                    oldvelocityh = velocityh\n",
    "                    oldvelocityo = velocityo\n",
    "\n",
    "                    velocityh = ((hero.get_location().x - oldh_x) ** 2 + (hero.get_location().y - oldh_y) ** 2 + (hero.get_location().z - oldh_z) ** 2) ** 0.5/0.1 * 2.23694\n",
    "                    velocityo = ((other_vehicle.get_location().x - oldo_x) ** 2 + (other_vehicle.get_location().y - oldo_y) ** 2 + (other_vehicle.get_location().z - oldo_z) ** 2) ** 0.5/0.1 * 2.23694\n",
    "                \n",
    "                    accelerationh = (velocityh * 0.44704 - oldvelocityh * 0.44704)/0.1\n",
    "                    accelerationo = (velocityo * 0.44704 - oldvelocityo * 0.44704)/0.1\n",
    "\n",
    "                    oldh_x = hero.get_location().x\n",
    "                    oldh_y = hero.get_location().y\n",
    "                    oldh_z = hero.get_location().z\n",
    "\n",
    "                    oldo_x = other_vehicle.get_location().x\n",
    "                    oldo_y = other_vehicle.get_location().y\n",
    "                    oldo_z = other_vehicle.get_location().z\n",
    "\n",
    "                if first_time == True:\n",
    "                    field = ['simulation_time',\n",
    "                    'ego_vehicle_x_coordinate',\n",
    "                    'ego_vehicle_y_coordinate',\n",
    "                    'ego_vehicle_z_coordinate',\n",
    "                    'ego_vehicle_velocity',\n",
    "                    'ego_vehicle_acceleration',\n",
    "                    'other_vehicle_x_coordinate',\n",
    "                    'other_vehicle_x_coordinate',\n",
    "                    'other_vehicle_x_coordinate',\n",
    "                    'other_vehicle_velocity',\n",
    "                    'other_vehicle_acceleration',\n",
    "                    ]\n",
    "        \n",
    "                    writer.writerow(field)\n",
    "\n",
    "                    first_time = False\n",
    "\n",
    "                writer.writerow(\n",
    "                    [start,\n",
    "                    hero.get_location().x,\n",
    "                    hero.get_location().y,\n",
    "                    hero.get_location().z,\n",
    "                    velocityh,\n",
    "                    accelerationh,\n",
    "                    other_vehicle.get_location().x,\n",
    "                    other_vehicle.get_location().y,\n",
    "                    other_vehicle.get_location().z,\n",
    "                    velocityo,\n",
    "                    accelerationo\n",
    "                    ])\n",
    "\n",
    "        df = pd.read_csv(full_csv_path)\n",
    "\n",
    "        df.at[crash_num, 'ego_vehicle_velocity'] = 0\n",
    "        df.at[crash_num, 'ego_vehicle_acceleration'] = 0\n",
    "        df.at[crash_num + 1, 'ego_vehicle_acceleration'] = 0\n",
    "\n",
    "        df.at[crash_num, 'other_vehicle_velocity'] = 0\n",
    "        df.at[crash_num, 'other_vehicle_acceleration'] = 0\n",
    "        df.at[crash_num + 1, 'other_vehicle_acceleration'] = 0\n",
    "\n",
    "        crash_num += 41\n",
    "\n",
    "        df.to_csv(full_csv_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Generation\n",
    "\n",
    "def process_image(image):\n",
    "    array = np.frombuffer(image.raw_data, dtype=np.dtype(\"uint8\"))\n",
    "    array = np.reshape(array, (image.height, image.width, 4))\n",
    "    array = array[:, :, :3]  # Remove alpha channel\n",
    "    return array\n",
    "\n",
    "def save_image(image, output_path):\n",
    "    image.save_to_disk(output_path)\n",
    "\n",
    "def image_callback_ego(image):\n",
    "    global frame_count\n",
    "    global output_directory_ego\n",
    "    output_path = os.path.join(output_directory_ego, f\"image_{frame_count:06d}.png\")\n",
    "    save_image(image, output_path)\n",
    "    frame_count += 1\n",
    "\n",
    "def image_callback_depth_ego(image):\n",
    "    global frame_count\n",
    "    global output_directory_depth_ego\n",
    "    output_path = os.path.join(output_directory_depth_ego, f\"image_{frame_count:06d}.png\")\n",
    "    save_image(image, output_path)\n",
    "    frame_count += 1\n",
    "\n",
    "def image_callback_other(image):\n",
    "    global frame_count\n",
    "    global output_directory_other\n",
    "    output_path = os.path.join(output_directory_other, f\"image_{frame_count:06d}.png\")\n",
    "    save_image(image, output_path)\n",
    "    frame_count += 1\n",
    "\n",
    "def image_callback_depth_other(image):\n",
    "    global frame_count\n",
    "    global output_directory_depth_other\n",
    "    output_path = os.path.join(output_directory_depth_other, f\"image_{frame_count:06d}.png\")\n",
    "    save_image(image, output_path)\n",
    "    frame_count += 1\n",
    "\n",
    "def create_images():\n",
    "    global frame_count\n",
    "    global output_directory_ego\n",
    "    global output_directory_other\n",
    "    global output_directory_depth_ego\n",
    "    global output_directory_depth_other\n",
    "\n",
    "    for i in range(len(time_list)):\n",
    "        time = time_list[i]\n",
    "        other_actor_id = other_actor_list[i]\n",
    "\n",
    "        start_time = time - 3\n",
    "        duration = time + 3\n",
    "        frame_count = 0\n",
    "\n",
    "        client = init_client(cfg['host'], cfg['port'])\n",
    "\n",
    "        run_replay(config_path, recorder_file_path, actor_id, start_time, duration)\n",
    "\n",
    "        # Get the world and set no rendering mode and create blueprint library to access rgb camera sensor\n",
    "        world = client.get_world()\n",
    "\n",
    "        settings = world.get_settings()\n",
    "        settings.fixed_delta_seconds = 0.04\n",
    "        world.apply_settings(settings)\n",
    "\n",
    "        blueprint_library = world.get_blueprint_library()\n",
    "        actor = world.get_actor(actor_id)\n",
    "\n",
    "        # Add a camera sensor to the vehicle\n",
    "        '''\n",
    "        blueprint = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "        blueprint.set_attribute('image_size_x', '1920')\n",
    "        blueprint.set_attribute('image_size_y', '1080')\n",
    "        blueprint.set_attribute('fov', '110')\n",
    "        blueprint.set_attribute('sensor_tick', '0.5')\n",
    "        '''\n",
    "        \n",
    "        #camera_transform = carla.Transform(carla.Location(x=0, z=1.7))\n",
    "        #'''\n",
    "        camera_bp = blueprint_library.find('sensor.camera.rgb')\n",
    "        camera_transform = carla.Transform(carla.Location(x=0.335, z=1.3875))\n",
    "        #'''\n",
    "\n",
    "        #camera = world.spawn_actor(blueprint, camera_transform, attach_to=actor)\n",
    "        camera = world.spawn_actor(camera_bp, camera_transform, attach_to=actor)\n",
    "        \n",
    "        camera.listen(image_callback_ego)\n",
    "\n",
    "        #output_directory_ego = project_directory + r\"crash_images/experiment_1/00-06-31/CogMod-v0_Town04_high_simple/distracted_1_repeat_1_ego_c\" + str(i + 1)\n",
    "        output_directory_ego = dir_path_images + r\"/\" + file_path + r\"_ego_c\" + str(i + 1)\n",
    "        output_directories_ego.append(output_directory_ego)\n",
    "\n",
    "        if not os.path.exists(output_directory_ego):\n",
    "            os.makedirs(output_directory_ego)\n",
    "        \n",
    "        snapshot = world.get_snapshot()\n",
    "        start_simulation_time = snapshot.timestamp.elapsed_seconds\n",
    "        end_simulation_time = start_simulation_time + 10\n",
    "\n",
    "        while True:\n",
    "            snapshot = world.get_snapshot()\n",
    "            current_time = snapshot.timestamp.elapsed_seconds\n",
    "\n",
    "            if current_time < end_simulation_time:\n",
    "                world.tick()\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        camera.stop()\n",
    "        camera.destroy()\n",
    "        actor.destroy()\n",
    "\n",
    "        #Other vehicle's perspective\n",
    "        start_time = time - 3\n",
    "        duration = time + 3\n",
    "        frame_count = 0\n",
    "\n",
    "        client = init_client(cfg['host'], cfg['port'])\n",
    "\n",
    "        run_replay(config_path, recorder_file_path, actor_id, start_time, duration)\n",
    "\n",
    "        # Get the world and set no rendering mode and create blueprint library to access rgb camera sensor\n",
    "        world = client.get_world()\n",
    "\n",
    "        other_actor = world.get_actor(other_actor_id)\n",
    "\n",
    "        # Add a camera sensor to the vehicle\n",
    "        camera_bp = blueprint_library.find('sensor.camera.rgb')\n",
    "        camera_transform = carla.Transform(carla.Location(x=1.6, z=1.7))\n",
    "        camera = world.spawn_actor(camera_bp, camera_transform, attach_to=other_actor)\n",
    "\n",
    "        camera.listen(image_callback_other)\n",
    "\n",
    "        #output_directory_other = project_directory + r\"crash_images/experiment_1/00-06-31/CogMod-v0_Town04_high_simple/distracted_1_repeat_1_other_c\" + str(i + 1)\n",
    "        output_directory_other = dir_path_images + r\"/\" + file_path + r\"_other_c\" + str(i + 1)\n",
    "        \n",
    "        output_directories_other.append(output_directory_other)\n",
    "        \n",
    "        if not os.path.exists(output_directory_other):\n",
    "            os.makedirs(output_directory_other)\n",
    "\n",
    "        snapshot = world.get_snapshot()\n",
    "        start_simulation_time = snapshot.timestamp.elapsed_seconds\n",
    "        end_simulation_time = start_simulation_time + 10\n",
    "\n",
    "        while True:\n",
    "            snapshot = world.get_snapshot()\n",
    "            current_time = snapshot.timestamp.elapsed_seconds\n",
    "\n",
    "            if current_time < end_simulation_time:\n",
    "                world.tick()\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        camera.stop()\n",
    "        camera.destroy()\n",
    "        other_actor.destroy()\n",
    "\n",
    "        #Top view perspective, following ego vehicle\n",
    "        start_time = time - 3\n",
    "        duration = time + 3\n",
    "        frame_count = 0\n",
    "\n",
    "        client = init_client(cfg['host'], cfg['port'])\n",
    "\n",
    "        run_replay(config_path, recorder_file_path, actor_id, start_time, duration)\n",
    "\n",
    "        # Get the world and set no rendering mode and create blueprint library to access rgb camera sensor\n",
    "        world = client.get_world()\n",
    "\n",
    "        other_actor = world.get_actor(other_actor_id)\n",
    "\n",
    "        # Add a camera sensor to the vehicle\n",
    "        camera_bp = blueprint_library.find('sensor.camera.rgb')\n",
    "\n",
    "        birds_eye_transform = carla.Transform(\n",
    "            carla.Location(x=0.0, y=0.0, z=20.0),  # Position the camera above the vehicle\n",
    "            carla.Rotation(pitch=-90, yaw=0, roll=0)  # Point the camera straight down\n",
    "        )\n",
    "        \n",
    "        camera = world.spawn_actor(camera_bp, birds_eye_transform, attach_to=actor)\n",
    "\n",
    "        camera.listen(image_callback_ego)\n",
    "\n",
    "        #output_directory_ego = project_directory + r\"crash_images/experiment_1/00-06-31/CogMod-v0_Town04_high_simple/distracted_1_repeat_1_top_ego_c\" + str(i + 1)\n",
    "        output_directory_ego = dir_path_images + r\"/\" + file_path + r\"_top_ego_c\" + str(i + 1)\n",
    "\n",
    "        output_directories_ego.append(output_directory_ego)\n",
    "        \n",
    "        if not os.path.exists(output_directory_ego):\n",
    "            os.makedirs(output_directory_ego)\n",
    "\n",
    "        snapshot = world.get_snapshot()\n",
    "        start_simulation_time = snapshot.timestamp.elapsed_seconds\n",
    "        end_simulation_time = start_simulation_time + 10\n",
    "\n",
    "        while True:\n",
    "            snapshot = world.get_snapshot()\n",
    "            current_time = snapshot.timestamp.elapsed_seconds\n",
    "\n",
    "            if current_time < end_simulation_time:\n",
    "                world.tick()\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        camera.stop()\n",
    "        camera.destroy()\n",
    "        other_actor.destroy()\n",
    "\n",
    "        #Top view perspective, following other vehicle\n",
    "        start_time = time - 3\n",
    "        duration = time + 3\n",
    "        frame_count = 0\n",
    "\n",
    "        client = init_client(cfg['host'], cfg['port'])\n",
    "\n",
    "        run_replay(config_path, recorder_file_path, actor_id, start_time, duration)\n",
    "\n",
    "        # Get the world and set no rendering mode and create blueprint library to access rgb camera sensor\n",
    "        world = client.get_world()\n",
    "\n",
    "        other_actor = world.get_actor(other_actor_id)\n",
    "\n",
    "        # Add a camera sensor to the vehicle\n",
    "        camera_bp = blueprint_library.find('sensor.camera.rgb')\n",
    "\n",
    "        birds_eye_transform = carla.Transform(\n",
    "            carla.Location(x=0.0, y=0.0, z=20.0),  # Position the camera above the vehicle\n",
    "            carla.Rotation(pitch=-90, yaw=0, roll=0)  # Point the camera straight down\n",
    "        )\n",
    "        \n",
    "        camera = world.spawn_actor(camera_bp, birds_eye_transform, attach_to=other_actor)\n",
    "\n",
    "        camera.listen(image_callback_other)\n",
    "\n",
    "        #output_directory_other = project_directory + r\"crash_images/experiment_1/00-06-31/CogMod-v0_Town04_high_simple/distracted_1_repeat_1_top_other_c\" + str(i + 1)\n",
    "        output_directory_other = dir_path_images + r\"/\" + file_path + r\"_top_other_c\" + str(i + 1)\n",
    "        \n",
    "        output_directories_other.append(output_directory_other)\n",
    "        \n",
    "        if not os.path.exists(output_directory_other):\n",
    "            os.makedirs(output_directory_other)\n",
    "\n",
    "        snapshot = world.get_snapshot()\n",
    "        start_simulation_time = snapshot.timestamp.elapsed_seconds\n",
    "        end_simulation_time = start_simulation_time + 10\n",
    "\n",
    "        while True:\n",
    "            snapshot = world.get_snapshot()\n",
    "            current_time = snapshot.timestamp.elapsed_seconds\n",
    "\n",
    "            if current_time < end_simulation_time:\n",
    "                world.tick()\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        camera.stop()\n",
    "        camera.destroy()\n",
    "        other_actor.destroy()\n",
    "\n",
    "        #Top view perspective, following ego vehicle\n",
    "        start_time = time - 3\n",
    "        duration = time + 3\n",
    "        frame_count = 0\n",
    "\n",
    "        client = init_client(cfg['host'], cfg['port'])\n",
    "\n",
    "        run_replay(config_path, recorder_file_path, actor_id, start_time, duration)\n",
    "\n",
    "        # Get the world and set no rendering mode and create blueprint library to access rgb camera sensor\n",
    "        world = client.get_world()\n",
    "\n",
    "        other_actor = world.get_actor(other_actor_id)\n",
    "\n",
    "        # Add a camera sensor to the vehicle\n",
    "        camera_bp = blueprint_library.find('sensor.camera.rgb')\n",
    "\n",
    "        rear_camera_transform = carla.Transform(\n",
    "            carla.Location(x=-10.0, z=3),  # Place the camera 2 meters behind the vehicle\n",
    "        )\n",
    "        \n",
    "        camera = world.spawn_actor(camera_bp, rear_camera_transform, attach_to=actor)\n",
    "\n",
    "        camera.listen(image_callback_ego)\n",
    "\n",
    "        #output_directory_ego = project_directory + r\"crash_images/experiment_1/00-06-31/CogMod-v0_Town04_high_simple/distracted_1_repeat_1_3rd_person_ego_c\" + str(i + 1)\n",
    "        output_directory_ego = dir_path_images + r\"/\" + file_path + r\"_3rd_person_ego_c\" + str(i + 1)\n",
    "\n",
    "        output_directories_ego.append(output_directory_ego)\n",
    "        \n",
    "        if not os.path.exists(output_directory_ego):\n",
    "            os.makedirs(output_directory_ego)\n",
    "\n",
    "        snapshot = world.get_snapshot()\n",
    "        start_simulation_time = snapshot.timestamp.elapsed_seconds\n",
    "        end_simulation_time = start_simulation_time + 10\n",
    "\n",
    "        while True:\n",
    "            snapshot = world.get_snapshot()\n",
    "            current_time = snapshot.timestamp.elapsed_seconds\n",
    "\n",
    "            if current_time < end_simulation_time:\n",
    "                world.tick()\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        camera.stop()\n",
    "        camera.destroy()\n",
    "        other_actor.destroy()\n",
    "\n",
    "        #3rd person view perspective, following ego vehicle\n",
    "        start_time = time - 3\n",
    "        duration = time + 3\n",
    "        frame_count = 0\n",
    "\n",
    "        client = init_client(cfg['host'], cfg['port'])\n",
    "\n",
    "        run_replay(config_path, recorder_file_path, actor_id, start_time, duration)\n",
    "\n",
    "        # Get the world and set no rendering mode and create blueprint library to access rgb camera sensor\n",
    "        world = client.get_world()\n",
    "\n",
    "        other_actor = world.get_actor(other_actor_id)\n",
    "\n",
    "        # Add a camera sensor to the vehicle\n",
    "        camera_bp = blueprint_library.find('sensor.camera.rgb')\n",
    "\n",
    "        rear_camera_transform = carla.Transform(\n",
    "            carla.Location(x=-10.0, z=3),  # Place the camera 2 meters behind the vehicle\n",
    "        )\n",
    "        \n",
    "        camera = world.spawn_actor(camera_bp, rear_camera_transform, attach_to=other_actor)\n",
    "\n",
    "        camera.listen(image_callback_other)\n",
    "\n",
    "        #output_directory_other = project_directory + r\"crash_images/experiment_1/00-06-31/CogMod-v0_Town04_high_simple/distracted_1_repeat_1_3rd_person_other_c\" + str(i + 1)\n",
    "        output_directory_other = dir_path_images + r\"/\" + file_path + r\"_3rd_person_other_c\" + str(i + 1)\n",
    "\n",
    "        output_directories_other.append(output_directory_other)\n",
    "        \n",
    "        if not os.path.exists(output_directory_other):\n",
    "            os.makedirs(output_directory_other)\n",
    "\n",
    "        snapshot = world.get_snapshot()\n",
    "        start_simulation_time = snapshot.timestamp.elapsed_seconds\n",
    "        end_simulation_time = start_simulation_time + 10\n",
    "\n",
    "        while True:\n",
    "            snapshot = world.get_snapshot()\n",
    "            current_time = snapshot.timestamp.elapsed_seconds\n",
    "\n",
    "            if current_time < end_simulation_time:\n",
    "                world.tick()\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        camera.stop()\n",
    "        camera.destroy()\n",
    "        other_actor.destroy()\n",
    "\n",
    "        #Depth camera perspective, following ego vehicle\n",
    "        start_time = time - 3\n",
    "        duration = time + 3\n",
    "        frame_count = 0\n",
    "\n",
    "        client = init_client(cfg['host'], cfg['port'])\n",
    "\n",
    "        run_replay(config_path, recorder_file_path, actor_id, start_time, duration)\n",
    "\n",
    "        world = client.get_world()\n",
    "\n",
    "        other_actor = world.get_actor(other_actor_id)\n",
    "\n",
    "        #camera_transform = carla.Transform(carla.Location(x=0, z=1.7))\n",
    "        #'''\n",
    "        camera_bp = blueprint_library.find('sensor.camera.depth')\n",
    "        camera_transform = carla.Transform(carla.Location(x=0.335, z=1.3875))\n",
    "        #'''\n",
    "\n",
    "        #camera = world.spawn_actor(blueprint, camera_transform, attach_to=actor)\n",
    "        camera = world.spawn_actor(camera_bp, camera_transform, attach_to=actor)\n",
    "\n",
    "        camera.listen(image_callback_depth_ego)\n",
    "\n",
    "        #output_directory_depth_ego = project_directory + r\"crash_images/experiment_1/00-06-31/CogMod-v0_Town04_high_simple/distracted_1_repeat_1_depth_ego_c\" + str(i + 1)\n",
    "        output_directory_depth_ego = dir_path_images + r\"/\" + file_path + r\"_depth_ego_c\" + str(i + 1)\n",
    "\n",
    "        output_directories_depth_ego.append(output_directory_depth_ego)\n",
    "\n",
    "        if not os.path.exists(output_directory_depth_ego):\n",
    "            os.makedirs(output_directory_depth_ego)\n",
    "        \n",
    "        snapshot = world.get_snapshot()\n",
    "        start_simulation_time = snapshot.timestamp.elapsed_seconds\n",
    "        end_simulation_time = start_simulation_time + 10\n",
    "\n",
    "        while True:\n",
    "            snapshot = world.get_snapshot()\n",
    "            current_time = snapshot.timestamp.elapsed_seconds\n",
    "\n",
    "            if current_time < end_simulation_time:\n",
    "                world.tick()\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        camera.stop()\n",
    "        camera.destroy()\n",
    "        other_actor.destroy()\n",
    "\n",
    "        #Other vehicle's perspective\n",
    "        start_time = time - 3\n",
    "        duration = time + 3\n",
    "        frame_count = 0\n",
    "\n",
    "        client = init_client(cfg['host'], cfg['port'])\n",
    "\n",
    "        run_replay(config_path, recorder_file_path, actor_id, start_time, duration)\n",
    "\n",
    "        # Get the world and set no rendering mode and create blueprint library to access rgb camera sensor\n",
    "        world = client.get_world()\n",
    "\n",
    "        other_actor = world.get_actor(other_actor_id)\n",
    "\n",
    "        # Add a camera sensor to the vehicle\n",
    "        camera_bp = blueprint_library.find('sensor.camera.depth')\n",
    "        camera_transform = carla.Transform(carla.Location(x=1.6, z=1.7))\n",
    "        camera = world.spawn_actor(camera_bp, camera_transform, attach_to=other_actor)\n",
    "\n",
    "        camera.listen(image_callback_depth_other)\n",
    "\n",
    "        #output_directory_depth_other = project_directory + r\"crash_images/experiment_1/00-06-31/CogMod-v0_Town04_high_simple/distracted_1_repeat_1_depth_other_c\" + str(i + 1)\n",
    "        output_directory_depth_other = dir_path_images + r\"/\" + file_path + r\"_depth_other_c\" + str(i + 1)\n",
    "\n",
    "        output_directories_depth_other.append(output_directory_depth_other)\n",
    "        \n",
    "        if not os.path.exists(output_directory_depth_other):\n",
    "            os.makedirs(output_directory_depth_other)\n",
    "\n",
    "        snapshot = world.get_snapshot()\n",
    "        start_simulation_time = snapshot.timestamp.elapsed_seconds\n",
    "        end_simulation_time = start_simulation_time + 10\n",
    "\n",
    "        while True:\n",
    "            snapshot = world.get_snapshot()\n",
    "            current_time = snapshot.timestamp.elapsed_seconds\n",
    "\n",
    "            if current_time < end_simulation_time:\n",
    "                world.tick()\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        camera.stop()\n",
    "        camera.destroy()\n",
    "        other_actor.destroy()\n",
    "    \n",
    "    return output_directories_ego, output_directories_other, output_directories_depth_ego, output_directories_depth_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image concatenation\n",
    "\n",
    "def file_list_ego(folder_paths):\n",
    "    for i in range(len(folder_paths)):\n",
    "        curr_dir = folder_paths[i]\n",
    "        files = os.listdir(curr_dir)\n",
    "        files.sort()\n",
    "        ego_images.append([os.path.join(curr_dir, f) for f in files])\n",
    "        #ego_images.append(os.listdir(curr_dir))\n",
    "        #ego_images[i].sort()\n",
    "\n",
    "def file_list_other(folder_paths):\n",
    "    for i in range(len(folder_paths)):\n",
    "        curr_dir = folder_paths[i]\n",
    "        files = os.listdir(curr_dir)\n",
    "        files.sort()\n",
    "        other_images.append([os.path.join(curr_dir, f) for f in files])\n",
    "        #other_images.append(os.listdir(curr_dir))\n",
    "        #other_images[i].sort()\n",
    "\n",
    "def file_list_depth_ego(folder_paths):\n",
    "    for i in range(len(folder_paths)):\n",
    "        curr_dir = folder_paths[i]\n",
    "        files = os.listdir(curr_dir)\n",
    "        files.sort()\n",
    "        depth_ego_images.append([os.path.join(curr_dir, f) for f in files])\n",
    "        #other_images.append(os.listdir(curr_dir))\n",
    "        #other_images[i].sort()\n",
    "\n",
    "def file_list_depth_other(folder_paths):\n",
    "    for i in range(len(folder_paths)):\n",
    "        curr_dir = folder_paths[i]\n",
    "        files = os.listdir(curr_dir)\n",
    "        files.sort()\n",
    "        depth_other_images.append([os.path.join(curr_dir, f) for f in files])\n",
    "        #other_images.append(os.listdir(curr_dir))\n",
    "        #other_images[i].sort()\n",
    "\n",
    "def file_list_exec(folder_paths_ego, folder_paths_other, folder_paths_depth_ego, folder_paths_depth_other):\n",
    "    file_list_ego(folder_paths_ego)\n",
    "    file_list_other(folder_paths_other)\n",
    "    file_list_depth_ego(folder_paths_depth_ego)\n",
    "    file_list_depth_other(folder_paths_depth_other)\n",
    "\n",
    "def concat_images(images, output_path):\n",
    "    concat_image_paths.append(output_path)\n",
    "    images_opened = [Image.open(image) for image in images]\n",
    "    widths, heights = zip(*(image.size for image in images_opened))\n",
    "\n",
    "    total_width = sum(widths)\n",
    "    total_height = sum(heights)\n",
    "    \n",
    "    concat_image = Image.new('RGBA', (total_width, total_height))\n",
    "    \n",
    "    x_offset = 0\n",
    "    for image in images_opened:\n",
    "        concat_image.paste(image, (x_offset, 0))\n",
    "        x_offset += image.width\n",
    "\n",
    "    concat_image.save(output_path)\n",
    "\n",
    "def concat_all():\n",
    "    for i in range(int(len(folder_paths_ego)/3)):\n",
    "        folder_paths_ego_concat.append(dir_path_concat + r\"/\" + file_path + r\"_ego_c\" + str(i + 1))\n",
    "        folder_paths_other_concat.append(dir_path_concat + r\"/\" + file_path + r\"_other_c\" + str(i + 1))\n",
    "        folder_paths_ego_concat.append(dir_path_concat + r\"/\" + file_path + r\"_top_ego_c\" + str(i + 1))\n",
    "        folder_paths_other_concat.append(dir_path_concat + r\"/\" + file_path + r\"_top_other_c\" + str(i + 1))\n",
    "        folder_paths_ego_concat.append(dir_path_concat + r\"/\" + file_path + r\"_3rd_person_ego_c\" + str(i + 1))\n",
    "        folder_paths_other_concat.append(dir_path_concat + r\"/\" + file_path + r\"_3rd_person_other_c\" + str(i + 1))\n",
    "\n",
    "    for i in range(int(len(folder_paths_depth_ego))):\n",
    "        folder_paths_depth_ego_concat.append(dir_path_concat + r\"/\" + file_path + r\"_depth_ego_c\" + str(i + 1))\n",
    "        folder_paths_depth_other_concat.append(dir_path_concat + r\"/\" + file_path + r\"_depth_other_c\" + str(i + 1))\n",
    "\n",
    "    print(\"Ego images length: {}, Ego images: {}\".format(len(ego_images), ego_images))\n",
    "\n",
    "    for i in range(len(folder_paths_ego)):\n",
    "        output_path = folder_paths_ego[i] + '_concatenated.png'\n",
    "        concat_images(ego_images[i], output_path)\n",
    "        shutil.move(output_path, folder_paths_ego_concat[i] + '_concatenated.png')\n",
    "\n",
    "    for i in range(len(folder_paths_other)):\n",
    "        output_path = folder_paths_other[i] + '_concatenated.png'\n",
    "        concat_images(other_images[i], output_path)\n",
    "        shutil.move(output_path, folder_paths_other_concat[i] + '_concatenated.png')\n",
    "\n",
    "    print(\"Length: {}, Folder Paths: {}\".format(len(folder_paths_depth_ego), folder_paths_depth_ego))\n",
    "    print(\"Depth ego images length: {}, Depth ego images: {}\".format(len(depth_ego_images), depth_ego_images))\n",
    "\n",
    "    for i in range(len(folder_paths_depth_ego)):\n",
    "        output_path = folder_paths_depth_ego[i] + '_concatenated.png'\n",
    "        print(\"Output path ego: {}\".format(output_path))\n",
    "        concat_images(depth_ego_images[i], output_path)\n",
    "        print(\"Successful concatenation\")\n",
    "        shutil.move(output_path, folder_paths_depth_ego_concat[i] + '_concatenated.png')\n",
    "\n",
    "    print(\"Length: {}, Folder Paths: {}\".format(len(folder_paths_depth_other), folder_paths_depth_other))\n",
    "    print(\"Depth other images length: {}, Depth other images: {}\".format(len(depth_other_images), depth_other_images))\n",
    "\n",
    "    for i in range(len(folder_paths_depth_other)):\n",
    "        output_path = folder_paths_depth_other[i] + '_concatenated.png'\n",
    "        print(\"Output path other: {}\".format(output_path))\n",
    "        concat_images(depth_other_images[i], output_path)\n",
    "        print(\"Successful concatenation\")\n",
    "        shutil.move(output_path, folder_paths_depth_other_concat[i] + '_concatenated.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GIF Generation\n",
    "\n",
    "def make_gif(frame_folder, gif_path):\n",
    "    images = glob.glob(f\"{frame_folder}/*.png\")\n",
    "\n",
    "    images.sort()\n",
    "\n",
    "    frames = [Image.open(image) for image in images]\n",
    "    frame_one = frames[0]\n",
    "    frame_one.save(gif_path, format=\"GIF\", append_images=frames, save_all=True, duration=100, loop=0)\n",
    "\n",
    "def gif_indiv_exec():    \n",
    "    for i in range(int(len(folder_paths_ego)/3)):\n",
    "        gif_path_ego.append(dir_path_gifs + r\"/\" + file_path + r\"_ego_c\" + str(i + 1) + r\".gif\")\n",
    "        gif_path_other.append(dir_path_gifs + r\"/\" + file_path + r\"_other_c\" + str(i + 1) + r\".gif\")\n",
    "        gif_path_ego.append(dir_path_gifs + r\"/\" + file_path + r\"_top_ego_c\" + str(i + 1) + r\".gif\")\n",
    "        gif_path_other.append(dir_path_gifs + r\"/\" + file_path + r\"_top_other_c\" + str(i + 1) + r\".gif\")\n",
    "        gif_path_ego.append(dir_path_gifs + r\"/\" + file_path + r\"_3rd_person_ego_c\" + str(i + 1) + r\".gif\")\n",
    "        gif_path_other.append(dir_path_gifs + r\"/\" + file_path + r\"_3rd_person_other_c\" + str(i + 1) + r\".gif\")\n",
    "\n",
    "    for i in range(len(folder_paths_depth_ego)):\n",
    "        gif_path_depth_ego.append(dir_path_gifs + r\"/\" + file_path + r\"_depth_ego_c\" + str(i + 1) + r\".gif\")\n",
    "        gif_path_depth_other.append(dir_path_gifs + r\"/\" + file_path + r\"_depth_other_c\" + str(i + 1) + r\".gif\")\n",
    "\n",
    "    for i in range(len(folder_paths_ego)):\n",
    "        make_gif(folder_paths_ego[i], gif_path_ego[i])\n",
    "        make_gif(folder_paths_other[i], gif_path_other[i])\n",
    "\n",
    "    for i in range(len(folder_paths_depth_ego)):\n",
    "        make_gif(folder_paths_depth_ego[i], gif_path_depth_ego[i])\n",
    "        make_gif(folder_paths_depth_other[i], gif_path_depth_other[i])\n",
    "\n",
    "def combined_gif():\n",
    "    gif_paths = []\n",
    "\n",
    "    for i in range(len(gif_path_ego)):\n",
    "        gif_paths.append(gif_path_ego[i])\n",
    "        gif_paths.append(gif_path_other[i])\n",
    "\n",
    "    gifs = [Image.open(gif_path) for gif_path in gif_paths]\n",
    "\n",
    "    rows, columns = 3, 2\n",
    "    canvas_width = 2400\n",
    "    canvas_height = 1200\n",
    "\n",
    "    # Get the number of frames to use (based on the longest GIF)\n",
    "    max_frames = 0\n",
    "    least_frames = 100\n",
    "\n",
    "    max_frames_list = []\n",
    "    least_frames_list = []\n",
    "\n",
    "    for i in range(len(time_list)):\n",
    "        max_frames = 0\n",
    "        least_frames = 100\n",
    "        for j in range(int(len(folder_paths_ego)/len(time_list))):\n",
    "            if len(os.listdir(folder_paths_ego[j + 3*i])) > max_frames:\n",
    "                max_frames = len(os.listdir(folder_paths_ego[j + 3*i]))\n",
    "            if len(os.listdir(folder_paths_ego[j + 3*i])) < least_frames:\n",
    "                least_frames = len(os.listdir(folder_paths_ego[j + 3*i]))\n",
    "            if len(os.listdir(folder_paths_other[j + 3*i])) > max_frames:\n",
    "                max_frames = len(os.listdir(folder_paths_other[j + 3*i]))\n",
    "            if len(os.listdir(folder_paths_other[j + 3*i])) < least_frames:\n",
    "                least_frames = len(os.listdir(folder_paths_other[j + 3*i]))\n",
    "\n",
    "        max_frames_list.append(max_frames)\n",
    "        least_frames_list.append(least_frames)\n",
    "\n",
    "    print(max_frames_list, least_frames_list)\n",
    "\n",
    "    # Create a list to hold the combined frames\n",
    "    combined_frames = []\n",
    "    frame_list = []\n",
    "\n",
    "    for a in range(len(time_list)):\n",
    "        for i in range(least_frames_list[a]):\n",
    "            for k in range(2):\n",
    "                for m in range(3):\n",
    "                    if k == 0:\n",
    "                        images = glob.glob(f\"{folder_paths_ego[m + a*3]}/*.png\")\n",
    "                        images.sort()\n",
    "                        frame_list.append(images[i])\n",
    "                    else:\n",
    "                        images = glob.glob(f\"{folder_paths_other[m + a*3]}/*.png\")\n",
    "                        images.sort()\n",
    "                        frame_list.append(images[i])\n",
    "\n",
    "            print(frame_list)\n",
    "\n",
    "            combined_image = Image.new('RGB', (canvas_width, canvas_height))\n",
    "            combined_image.paste(im = Image.open(frame_list[0]), box = (0, 0))\n",
    "            combined_image.paste(im = Image.open(frame_list[1]), box = (800, 0))\n",
    "            combined_image.paste(im = Image.open(frame_list[2]), box = (1600, 0))\n",
    "            combined_image.paste(im = Image.open(frame_list[3]), box = (0, 600))\n",
    "            combined_image.paste(im = Image.open(frame_list[4]), box = (800, 600))\n",
    "            combined_image.paste(im = Image.open(frame_list[5]), box = (1600, 600))\n",
    "\n",
    "            combined_image.resize((int(canvas_width * 0.3), int(canvas_height * 0.3)), Image.LANCZOS)\n",
    "\n",
    "            combined_frames.append(combined_image)\n",
    "\n",
    "            frame_list = []\n",
    "\n",
    "        frame_one = combined_frames[0]\n",
    "\n",
    "        frame_one.save(\n",
    "            dir_path_gifs + r\"/\" + file_path + r\"_combined_c\" + str(a + 1) + \".gif\",\n",
    "            format=\"GIF\",\n",
    "            append_images=combined_frames[1:],\n",
    "            save_all=True,\n",
    "            duration=120,\n",
    "            loop=0\n",
    "        )\n",
    "    \n",
    "        combined_frames = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Town: Town04, Traffic Density: high, Date: 00-06-31, Driver Condition: distracted, Trial Number: , Folder: CogMod-v0_Town04_high_simple, File Path: distracted_1_repeat_\n",
      "/home/ubuntu/vihaan-devel/carla/sip-report-gen/carla-roach-0.9.13/config/benchmark.yaml\n",
      "/home/ubuntu/vihaan-devel/carla/sip-report-gen/carla-roach-0.9.13/outputs/experiment_1/00-06-31/diagnostics/CogMod-v0_Town04_high_simple/distracted_1_repeat_.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/vihaan-devel/carla/CARLA_0.9.13/CarlaUE4.sh: line 5:  4471 Killed                  \"$UE4_PROJECT_ROOT/CarlaUE4/Binaries/Linux/CarlaUE4-Linux-Shipping\" CarlaUE4 \"$@\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4294/1013622613.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_4294/1013622613.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecorder_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mcarla_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mcarla_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4294/3642172525.py\u001b[0m in \u001b[0;36mcarla_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mserver_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCarlaServerManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'carla_sh_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'port'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_sleep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mserver_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mserver_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vihaan-devel/carla/sip-report-gen/carla-roach-0.9.13/utils_cogmod/server_utils.py\u001b[0m in \u001b[0;36mstop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mkill_carla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_t_sleep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Kill Carla Servers!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    global config_path\n",
    "\n",
    "    global town, traffic_density, date, driver_condition, trial_num, folder, file_path\n",
    "    \n",
    "    global recorder_file_path\n",
    "\n",
    "    global actor_id\n",
    "\n",
    "    global gaze, intensity, time, time_list, valid_gazes, filename, filename2, step, simulation_time, collision_type, other_actor_id, other_actor_list, other_actor_type_id\n",
    "\n",
    "    global output_directories_ego, output_directories_other, output_directories_depth_ego, output_directories_depth_other\n",
    "\n",
    "    global folder_paths_ego, folder_paths_other, folder_paths_depth_ego, folder_paths_depth_other\n",
    "\n",
    "    global folder_paths_ego_concat, folder_paths_other_concat, folder_paths_depth_ego_concat, folder_paths_depth_other_concat\n",
    "\n",
    "    global ego_images, other_images, depth_ego_images, depth_other_images\n",
    "\n",
    "    global concat_image_paths\n",
    "\n",
    "    global gif_path_ego, gif_path_other, gif_path_depth_ego, gif_path_depth_other\n",
    "\n",
    "    global dir_path_images, dir_path_concat, dir_path_gifs\n",
    "\n",
    "    config_path = project_directory + r\"config/benchmark.yaml\"\n",
    "    recorder_file_path = project_directory + r\"accident_dataset/distracted_driver/Town04/low/episode_1.log\"\n",
    "    recorder_file_path = project_directory + r\"outputs/experiment_1/00-06-31/diagnostics/CogMod-v0_Town04_high_simple/distracted_1_repeat_1.log\"\n",
    "    town, traffic_density, date, driver_condition, trial_num, folder, file_path = user_input()\n",
    "    recorder_file_path = project_directory + r\"outputs/experiment_1/\" + date + r\"/diagnostics/\" + folder + r\"/\" + file_path + \".log\"\n",
    "\n",
    "    print(config_path)\n",
    "    print(recorder_file_path)\n",
    "    \n",
    "    carla_init()\n",
    "    \n",
    "    carla_client()\n",
    "\n",
    "    actor_id = crash_gen()\n",
    "    \n",
    "    gaze, intensity, time, time_list, valid_gazes, filename, filename2, step, simulation_time, collision_type, other_actor_id, other_actor_list, other_actor_type_id = crash_info()\n",
    "\n",
    "    store_basic_crash_info()\n",
    "\n",
    "    csv_generation()\n",
    "\n",
    "    output_directories_ego = []\n",
    "    output_directories_other = []\n",
    "    output_directories_depth_ego = []\n",
    "    output_directories_depth_other = []\n",
    "\n",
    "    dir_path_images = project_directory + r\"crash_images/experiment_1/\" + date + r\"/\" + folder + r\"/\" + file_path\n",
    "    os.makedirs(dir_path_images)\n",
    "\n",
    "    output_directories_ego, output_directories_other, output_directories_depth_ego, output_directories_depth_other = create_images()\n",
    "\n",
    "    folder_paths_ego = output_directories_ego\n",
    "    folder_paths_other = output_directories_other\n",
    "    folder_paths_depth_ego = output_directories_depth_ego\n",
    "    folder_paths_depth_other = output_directories_depth_other\n",
    "\n",
    "    folder_paths_ego_concat = []\n",
    "    folder_paths_other_concat = []\n",
    "    folder_paths_depth_ego_concat = []\n",
    "    folder_paths_depth_other_concat = []\n",
    "\n",
    "    dir_path_concat = project_directory + r\"concat_images/experiment_1/\" + date + r\"/\" + folder + r\"/\" + file_path\n",
    "    os.makedirs(dir_path_concat)\n",
    "        \n",
    "    ego_images = []\n",
    "    other_images = []\n",
    "    depth_ego_images = []\n",
    "    depth_other_images = []\n",
    "\n",
    "    concat_image_paths = []\n",
    "\n",
    "    file_list_exec(folder_paths_ego, folder_paths_other, folder_paths_depth_ego, folder_paths_depth_other)\n",
    "\n",
    "    concat_all()\n",
    "    \n",
    "    dir_path_gifs = project_directory + r\"gifs/experiment_1/\" + date + r\"/\" + folder + r\"/\" + file_path\n",
    "    os.makedirs(dir_path_gifs)\n",
    "\n",
    "    gif_path_ego = []\n",
    "    gif_path_other = []\n",
    "    gif_path_depth_ego = []\n",
    "    gif_path_depth_other = []\n",
    "\n",
    "    print(\"hi0\")\n",
    "    gif_indiv_exec()\n",
    "    print(\"hi1\")\n",
    "\n",
    "    combined_gif()\n",
    "    print(\"hi2\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport base64\\nimport requests\\nimport os\\nfrom openai import OpenAI\\n\\nclient = OpenAI()\\n\\napi_key = os.environ[\\'OPENAI_API_KEY\\']\\n\\nencoded_images = []\\n\\ndef encode_image_1(image_path):\\n  with open(image_path, \"rb\") as image_file:\\n    return base64.b64encode(image_file.read()).decode(\\'utf-8\\')\\n\\ndef base64_image_size(base64_string):\\n    # Calculate the size of the base64 string in bytes\\n    base64_bytes = base64_string.encode(\\'utf-8\\')\\n    byte_size = len(base64_bytes)\\n    \\n    # Convert bytes to megabytes (1 MB = 1,048,576 bytes)\\n    megabyte_size = byte_size / (1024 * 1024)\\n    \\n    return megabyte_size\\n\\n# Path to your image\\nimage_path = \"/home/ubuntu/vihaan-devel/carla/sip-report-gen/carla-roach-0.9.13/crash_images/experiment_1/00-14-25/CogMod-v0_Town04_high_simple/distracted_1_repeat_1_other_c2_concatenated.png\"\\n#image_path = \"/home/ubuntu/Downloads/test.jpg\"\\n\\nfile_stats = os.stat(image_path)\\nprint(f\\'File Size in MegaBytes is {file_stats.st_size / (1024 * 1024)}\\')\\n\\n# Getting the base64 string\\nbase64_image = encode_image_1(image_path)\\n\\nimgsizeb64 = base64_image_size(base64_image)\\nprint(imgsizeb64)\\n\\nheaders = {\\n  \"Content-Type\": \"application/json\",\\n  \"Authorization\": f\"Bearer {api_key}\"\\n}\\n\\npayload = {\\n  \"model\": \"gpt-4o-mini\",\\n  \"messages\": [\\n    {\\n      \"role\": \"user\",\\n      \"content\": [\\n        {\\n          \"type\": \"text\",\\n          \"text\": \"What’s in this image?\"\\n        },\\n        {\\n          \"type\": \"image_url\",\\n          \"image_url\": {\\n            \"url\": f\"data:image/png;base64,{base64_image}\"\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \"max_tokens\": 300\\n}\\n\\nresponse = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\\n\\nprint(response.json())\\n\\n\\ndef encode_image(image_path_folder):\\n    for i in range(len(image_path_folder)):\\n      with open(image_path_folder[i], \"rb\") as image_file:\\n          encoded_images.append(base64.b64encode(image_file.read()).decode(\\'utf-8\\'))\\n\\nif __name__ == \"__main__\":\\n   encode_image(concat_image_paths)\\n\\ncompletion = client.chat.completions.create(\\n  model = \"gpt-4o-mini\",\\n  messages = [\\n     {\\n        \"role\": \"user\",\\n        \"content\": [\\n           {\\n              \"type\": \"text\",\\n              \"text\": \"Given the following information please create a DMV style report of the following accident in the Carla simulation. I will be giving you the following information of the crash: Images of the crash from the perspectives of both the ego vehicle and other vehicle (PS, if the other vehicle is a firetruck, I won\\'t be able to provide adequate FOV images), 4 human narrative interpretations of the accident, A JSON file including details of the time of the accident as well as the intensity, etc., 2 CSV files (1 includes the location of both vehicles, their acceleration (m/s^2), and velocities (mph). The other includes the gaze direction of the ego vehicle (where the driver was looking) at different time steps). The files are attached. Here are the human interpreted narratives: 1.) Actor 1 merged smoothly but Actor 2 (a big truck) was driving quickly and wasn’t able to slow down causing a crash. 2.) The hero car is trying to make a double lane change on the highway. After the first lane change, a firetruck hits the hero car from behind. 3.) Actor 2 was distracted and collided into actor one. 4.) Firetruck isn\\'t able to slow down in time to avoid collision with Lincoln. The firetruck ends up backending the Lincoln. Liability is very highly debatable since trucks are known to need a while to slow down since their mass is so great. Make your OWN interpretation of the accident in a DMV style report.\"\\n           },\\n           {\\n              \"type\": \"image_url\",\\n              \"image_url\": {\\n                 \"url\": encoded_images[0]\\n              }\\n           },\\n           {\\n              \"type\": \"image_url\",\\n              \"image_url\": {\\n                 \"url\": encoded_images[1]\\n              }\\n           },\\n           {\\n              \"type\": \"image_url\",\\n              \"image_url\": {\\n                 \"url\": encoded_images[2]\\n              }\\n           },\\n           {\\n              \"type\": \"image_url\",\\n              \"image_url\": {\\n                 \"url\": encoded_images[3]\\n              }\\n           },\\n        ]\\n     }\\n  ]\\n)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LLM Accident Report Generation Experimentation\n",
    "\n",
    "'''\n",
    "import base64\n",
    "import requests\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "encoded_images = []\n",
    "\n",
    "def encode_image_1(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def base64_image_size(base64_string):\n",
    "    # Calculate the size of the base64 string in bytes\n",
    "    base64_bytes = base64_string.encode('utf-8')\n",
    "    byte_size = len(base64_bytes)\n",
    "    \n",
    "    # Convert bytes to megabytes (1 MB = 1,048,576 bytes)\n",
    "    megabyte_size = byte_size / (1024 * 1024)\n",
    "    \n",
    "    return megabyte_size\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"/home/ubuntu/vihaan-devel/carla/sip-report-gen/carla-roach-0.9.13/crash_images/experiment_1/00-14-25/CogMod-v0_Town04_high_simple/distracted_1_repeat_1_other_c2_concatenated.png\"\n",
    "#image_path = \"/home/ubuntu/Downloads/test.jpg\"\n",
    "\n",
    "file_stats = os.stat(image_path)\n",
    "print(f'File Size in MegaBytes is {file_stats.st_size / (1024 * 1024)}')\n",
    "\n",
    "# Getting the base64 string\n",
    "base64_image = encode_image_1(image_path)\n",
    "\n",
    "imgsizeb64 = base64_image_size(base64_image)\n",
    "print(imgsizeb64)\n",
    "\n",
    "headers = {\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "payload = {\n",
    "  \"model\": \"gpt-4o-mini\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"What’s in this image?\"\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": f\"data:image/png;base64,{base64_image}\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"max_tokens\": 300\n",
    "}\n",
    "\n",
    "response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "print(response.json())\n",
    "\n",
    "\n",
    "def encode_image(image_path_folder):\n",
    "    for i in range(len(image_path_folder)):\n",
    "      with open(image_path_folder[i], \"rb\") as image_file:\n",
    "          encoded_images.append(base64.b64encode(image_file.read()).decode('utf-8'))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   encode_image(concat_image_paths)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model = \"gpt-4o-mini\",\n",
    "  messages = [\n",
    "     {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "           {\n",
    "              \"type\": \"text\",\n",
    "              \"text\": \"Given the following information please create a DMV style report of the following accident in the Carla simulation. I will be giving you the following information of the crash: Images of the crash from the perspectives of both the ego vehicle and other vehicle (PS, if the other vehicle is a firetruck, I won't be able to provide adequate FOV images), 4 human narrative interpretations of the accident, A JSON file including details of the time of the accident as well as the intensity, etc., 2 CSV files (1 includes the location of both vehicles, their acceleration (m/s^2), and velocities (mph). The other includes the gaze direction of the ego vehicle (where the driver was looking) at different time steps). The files are attached. Here are the human interpreted narratives: 1.) Actor 1 merged smoothly but Actor 2 (a big truck) was driving quickly and wasn’t able to slow down causing a crash. 2.) The hero car is trying to make a double lane change on the highway. After the first lane change, a firetruck hits the hero car from behind. 3.) Actor 2 was distracted and collided into actor one. 4.) Firetruck isn't able to slow down in time to avoid collision with Lincoln. The firetruck ends up backending the Lincoln. Liability is very highly debatable since trucks are known to need a while to slow down since their mass is so great. Make your OWN interpretation of the accident in a DMV style report.\"\n",
    "           },\n",
    "           {\n",
    "              \"type\": \"image_url\",\n",
    "              \"image_url\": {\n",
    "                 \"url\": encoded_images[0]\n",
    "              }\n",
    "           },\n",
    "           {\n",
    "              \"type\": \"image_url\",\n",
    "              \"image_url\": {\n",
    "                 \"url\": encoded_images[1]\n",
    "              }\n",
    "           },\n",
    "           {\n",
    "              \"type\": \"image_url\",\n",
    "              \"image_url\": {\n",
    "                 \"url\": encoded_images[2]\n",
    "              }\n",
    "           },\n",
    "           {\n",
    "              \"type\": \"image_url\",\n",
    "              \"image_url\": {\n",
    "                 \"url\": encoded_images[3]\n",
    "              }\n",
    "           },\n",
    "        ]\n",
    "     }\n",
    "  ]\n",
    ")\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-python-370-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
